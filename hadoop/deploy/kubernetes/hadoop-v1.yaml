apiVersion: v1
kind: Namespace
metadata:
  name: bigdata2
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-config
  namespace: bigdata2
data:
  core-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>fs.default.name</name>
        <value>hdfs://namenode:8020</value>
      </property>
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://namenode:8020</value>
      </property>
    </configuration>
  hdfs-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>dfs.namenode.rpc-address</name>
        <value>namenode:8020</value>
      </property>
      <property>
        <name>dfs.replication</name>
        <value>1</value>
      </property>
      <property>
        <name>dfs.namenode.name.dir</name>
        <value>/tmp/hadoop-root/dfs/name</value>
      </property>
      <property>
        <name>dfs.datanode.data.dir</name>
        <value>/tmp/hadoop-root/dfs/data</value>
      </property>
      <property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
      </property>
    </configuration>
  mapred-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
      </property>
      <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
      </property>
      <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
      </property>
      <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
      </property>
    </configuration>
  yarn-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>resourcemanager</value>
      </property>
      <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>yarn.nodemanager.delete.debug-delay-sec</name>
        <value>600</value>
      </property>
      <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
      </property>
      <property>
        <name>yarn.resourcemanager.address</name>
        <value>resourcemanager:8032</value>
      </property>
    </configuration>
  capacity-scheduler.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>yarn.scheduler.capacity.maximum-applications</name>
        <value>10000</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
        <value>0.1</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.resource-calculator</name>
        <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.queues</name>
        <value>default</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.capacity</name>
        <value>100</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
        <value>1</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
        <value>100</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.state</name>
        <value>RUNNING</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
        <value>*</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
        <value>*</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.node-locality-delay</name>
        <value>40</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.queue-mappings</name>
        <value></value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.queue-mappings-override.enable</name>
        <value>false</value>
      </property>
    </configuration>
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-test-script
  namespace: bigdata2
data:
  test.sh: |
    #!/bin/bash
    echo "Hadoop ResourceManager Test Script"
    echo "Current Hadoop Version: 3.1.1"
    echo "HDFS Status: $(hdfs dfsadmin -report | grep 'DFS Used%')"
    echo "YARN Status: $(yarn node -list)"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: namenode-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: datanode-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: resourcemanager-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nodemanager-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: namenode
  namespace: bigdata2
  labels:
    app: hadoop
    component: namenode
spec:
  hostname: namenode
  containers:
  - name: namenode
    image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
    securityContext:
      runAsUser: 0
      runAsGroup: 0
    command: ["/bin/sh", "-c"]
    args:
      - |
        set -e
        echo "=== 校验配置文件 ==="
        ls -l /opt/hadoop/etc/hadoop/*.xml
        cat /opt/hadoop/etc/hadoop/core-site.xml
        echo "======================"
        mkdir -p /tmp/hadoop-root/dfs/name
        chmod -R 777 /tmp/hadoop-root/
        if [ ! -d "/tmp/hadoop-root/dfs/name/current" ]; then
          echo "=== 首次启动，格式化Namenode ==="
          hdfs namenode -format -force -nonInteractive || { echo "格式化失败"; exit 1; }
        fi
        echo "=== 启动Namenode ==="
        hdfs namenode
    ports:
    - containerPort: 9870
    - containerPort: 8020
    - containerPort: 9868
    env:
      - name: HADOOP_HOME
        value: /opt/hadoop
      - name: PATH
        value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
      - name: HADOOP_LOG_DIR
        value: /tmp/hadoop-logs
    volumeMounts:
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/core-site.xml
      subPath: core-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
      subPath: hdfs-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
      subPath: mapred-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
      subPath: yarn-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
      subPath: capacity-scheduler.xml
      readOnly: true
    - name: namenode-data
      mountPath: /tmp/hadoop-root
    - name: namenode-logs
      mountPath: /tmp/hadoop-logs
  volumes:
  - name: hadoop-config
    configMap:
      name: hadoop-config
      defaultMode: 0755
  - name: namenode-data
    persistentVolumeClaim:
      claimName: namenode-pvc
  - name: namenode-logs
    emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: namenode
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: namenode
  ports:
  - name: webui
    port: 9870
    targetPort: 9870
  - name: rpc
    port: 8020
    targetPort: 8020
  - name: datanode-http
    port: 9868
    targetPort: 9868
---
apiVersion: v1
kind: Pod
metadata:
  name: datanode
  namespace: bigdata2
  labels:
    app: hadoop
    component: datanode
spec:
  hostname: datanode
  containers:
  - name: datanode
    image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
    securityContext:
      runAsUser: 0
      runAsGroup: 0
    command: ["/bin/sh", "-c"]
    args:
      - |
        set -e
        echo "=== 等待Namenode就绪 ==="
        for i in {1..30}; do
          if nc -z namenode 8020; then
            echo "Namenode已就绪！"
            break
          fi
          echo "Namenode未就绪，等待10秒..."
          sleep 10
        done
        echo "=== 校验配置文件 ==="
        ls -l /opt/hadoop/etc/hadoop/*.xml
        mkdir -p /tmp/hadoop-root/dfs/data
        chmod -R 777 /tmp/hadoop-root/
        echo "=== 启动Datanode ==="
        hdfs datanode
    ports:
    - containerPort: 9864
    - containerPort: 9866
    - containerPort: 9867
    env:
      - name: HADOOP_HOME
        value: /opt/hadoop
      - name: PATH
        value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
      - name: HADOOP_LOG_DIR
        value: /tmp/hadoop-logs
    volumeMounts:
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/core-site.xml
      subPath: core-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
      subPath: hdfs-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
      subPath: mapred-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
      subPath: yarn-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
      subPath: capacity-scheduler.xml
      readOnly: true
    - name: datanode-data
      mountPath: /tmp/hadoop-root
    - name: datanode-logs
      mountPath: /tmp/hadoop-logs
  volumes:
  - name: hadoop-config
    configMap:
      name: hadoop-config
      defaultMode: 0755
  - name: datanode-data
    persistentVolumeClaim:
      claimName: datanode-pvc
  - name: datanode-logs
    emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: datanode
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: datanode
  ports:
  - name: webui
    port: 9864
    targetPort: 9864
  - name: data-transfer
    port: 9866
    targetPort: 9866
  - name: ipc
    port: 9867
    targetPort: 9867
---
apiVersion: v1
kind: Pod
metadata:
  name: resourcemanager
  namespace: bigdata2
  labels:
    app: hadoop
    component: resourcemanager
spec:
  hostname: resourcemanager
  containers:
  - name: resourcemanager
    image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
    securityContext:
      runAsUser: 0
      runAsGroup: 0
    command: ["/bin/sh", "-c"]
    args:
      - |
        set -e
        echo "=== 等待Namenode就绪 ==="
        for i in {1..30}; do
          if nc -z namenode 8020; then
            echo "Namenode已就绪！"
            break
          fi
          echo "Namenode未就绪，等待10秒..."
          sleep 10
        done
        echo "=== 校验配置文件 ==="
        ls -l /opt/hadoop/etc/hadoop/*.xml
        mkdir -p /tmp/hadoop-yarn
        chmod -R 777 /tmp/hadoop-yarn
        echo "=== 启动ResourceManager ==="
        yarn resourcemanager
    ports:
    - containerPort: 8088
    - containerPort: 8030
    - containerPort: 8031
    - containerPort: 8032
    env:
      - name: HADOOP_HOME
        value: /opt/hadoop
      - name: PATH
        value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
      - name: HADOOP_LOG_DIR
        value: /tmp/hadoop-logs
    volumeMounts:
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/core-site.xml
      subPath: core-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
      subPath: hdfs-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
      subPath: mapred-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
      subPath: yarn-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
      subPath: capacity-scheduler.xml
      readOnly: true
    - name: resourcemanager-data
      mountPath: /tmp/hadoop-yarn
    - name: test-script
      mountPath: /opt/test.sh
      subPath: test.sh
      readOnly: false
    - name: resourcemanager-logs
      mountPath: /tmp/hadoop-logs
  volumes:
  - name: hadoop-config
    configMap:
      name: hadoop-config
      defaultMode: 0755
  - name: resourcemanager-data
    persistentVolumeClaim:
      claimName: resourcemanager-pvc
  - name: test-script
    configMap:
      name: hadoop-test-script
      defaultMode: 0755
  - name: resourcemanager-logs
    emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: resourcemanager
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: resourcemanager
  ports:
  - name: webui
    port: 8088
    targetPort: 8088
  - name: rpc
    port: 8030
    targetPort: 8030
  - name: scheduler
    port: 8031
    targetPort: 8031
  - name: yarn-rpc
    port: 8032
    targetPort: 8032
---
apiVersion: v1
kind: Pod
metadata:
  name: nodemanager
  namespace: bigdata2
  labels:
    app: hadoop
    component: nodemanager
spec:
  hostname: nodemanager
  containers:
  - name: nodemanager
    image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
    securityContext:
      runAsUser: 0
      runAsGroup: 0
    command: ["/bin/sh", "-c"]
    args:
      - |
        set -e
        echo "=== 等待ResourceManager就绪 ==="
        for i in {1..30}; do
          if nc -z resourcemanager 8032; then
            echo "ResourceManager已就绪！"
            break
          fi
          echo "ResourceManager未就绪，等待10秒..."
          sleep 10
        done
        echo "=== 校验配置文件 ==="
        ls -l /opt/hadoop/etc/hadoop/*.xml
        mkdir -p /tmp/hadoop-yarn-nm
        chmod -R 777 /tmp/hadoop-yarn-nm
        echo "=== 启动NodeManager ==="
        yarn nodemanager
    ports:
    - containerPort: 8042
    - containerPort: 8040
    env:
      - name: HADOOP_HOME
        value: /opt/hadoop
      - name: PATH
        value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
      - name: HADOOP_LOG_DIR
        value: /tmp/hadoop-logs
    volumeMounts:
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/core-site.xml
      subPath: core-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
      subPath: hdfs-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
      subPath: mapred-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
      subPath: yarn-site.xml
      readOnly: true
    - name: hadoop-config
      mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
      subPath: capacity-scheduler.xml
      readOnly: true
    - name: nodemanager-data
      mountPath: /tmp/hadoop-yarn-nm
    - name: nodemanager-logs
      mountPath: /tmp/hadoop-logs
  volumes:
  - name: hadoop-config
    configMap:
      name: hadoop-config
      defaultMode: 0755
  - name: nodemanager-data
    persistentVolumeClaim:
      claimName: nodemanager-pvc
  - name: nodemanager-logs
    emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: nodemanager
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: nodemanager
  ports:
  - name: webui
    port: 8042
    targetPort: 8042
  - name: localizer
    port: 8040
    targetPort: 8040
