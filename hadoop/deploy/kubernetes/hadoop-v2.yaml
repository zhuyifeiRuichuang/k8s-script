# 命名空间
apiVersion: v1
kind: Namespace
metadata:
  name: bigdata2
---
# Hadoop XML配置ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-config
  namespace: bigdata2
data:
  core-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>fs.default.name</name>
        <value>hdfs://namenode:8020</value>
      </property>
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://namenode:8020</value>
      </property>
    </configuration>

  hdfs-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>dfs.namenode.rpc-address</name>
        <value>namenode:8020</value>
      </property>
      <property>
        <name>dfs.replication</name>
        <value>1</value>
      </property>
      <property>
        <name>dfs.namenode.name.dir</name>
        <value>/tmp/hadoop-root/dfs/name</value>
      </property>
      <property>
        <name>dfs.datanode.data.dir</name>
        <value>/tmp/hadoop-root/dfs/data</value>
      </property>
      <property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
      </property>
    </configuration>

  mapred-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
      </property>
      <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
      </property>
      <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
      </property>
      <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
      </property>
    </configuration>

  yarn-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>resourcemanager</value>
      </property>
      <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>yarn.nodemanager.delete.debug-delay-sec</name>
        <value>600</value>
      </property>
      <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
      </property>
      <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
      </property>
      <property>
        <name>yarn.resourcemanager.address</name>
        <value>resourcemanager:8032</value>
      </property>
    </configuration>

  capacity-scheduler.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
      <property>
        <name>yarn.scheduler.capacity.maximum-applications</name>
        <value>10000</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
        <value>0.1</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.resource-calculator</name>
        <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.queues</name>
        <value>default</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.capacity</name>
        <value>100</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
        <value>1</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
        <value>100</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.state</name>
        <value>RUNNING</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
        <value>*</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
        <value>*</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.node-locality-delay</name>
        <value>40</value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.queue-mappings</name>
        <value></value>
      </property>
      <property>
        <name>yarn.scheduler.capacity.queue-mappings-override.enable</name>
        <value>false</value>
      </property>
    </configuration>
---
# 测试脚本ConfigMap（不变）
apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-test-script
  namespace: bigdata2
data:
  test.sh: |
    #!/bin/bash
    echo "Hadoop ResourceManager Test Script"
    echo "Current Hadoop Version: 3.1.1"
    echo "HDFS Status: $(hdfs dfsadmin -report | grep 'DFS Used%')"
    echo "YARN Status: $(yarn node -list)"
---
# PVC配置（不变）
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: namenode-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: datanode-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: resourcemanager-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nodemanager-pvc
  namespace: bigdata2
spec:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "local"
  resources:
    requests:
      storage: 10Gi
---
# 1. Namenode Deployment + Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: namenode
  namespace: bigdata2
  labels:
    app: hadoop
    component: namenode
spec:
  replicas: 1  # Namenode通常单副本
  selector:
    matchLabels:
      app: hadoop
      component: namenode
  strategy:
    type: Recreate  # 有状态组件使用重建策略，避免并行实例冲突
  template:
    metadata:
      labels:
        app: hadoop
        component: namenode
    spec:
      containers:
      - name: namenode
        image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
        securityContext:
          runAsUser: 0
          runAsGroup: 0
        command: ["/bin/sh", "-c"]
        args:
          - |
            set -e
            # 校验配置文件
            echo "=== 校验配置文件 ==="
            ls -l /opt/hadoop/etc/hadoop/*.xml
            cat /opt/hadoop/etc/hadoop/core-site.xml
            echo "======================"
            # 确保数据目录存在并授权
            mkdir -p /tmp/hadoop-root/dfs/name
            chmod -R 777 /tmp/hadoop-root/
            # 首次格式化Namenode
            if [ ! -d "/tmp/hadoop-root/dfs/name/current" ]; then
              echo "=== 首次启动，格式化Namenode ==="
              hdfs namenode -format -force -nonInteractive || { echo "格式化失败"; exit 1; }
            fi
            # 启动Namenode
            echo "=== 启动Namenode ==="
            hdfs namenode
        ports:
        - containerPort: 9870
        - containerPort: 8020
        - containerPort: 9868
        env:
          - name: HADOOP_HOME
            value: /opt/hadoop
          - name: PATH
            value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
          - name: HADOOP_LOG_DIR
            value: /tmp/hadoop-logs
        volumeMounts:
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/core-site.xml
          subPath: core-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
          subPath: hdfs-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
          subPath: mapred-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
          subPath: yarn-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
          subPath: capacity-scheduler.xml
          readOnly: true
        - name: namenode-data
          mountPath: /tmp/hadoop-root
        - name: namenode-logs
          mountPath: /tmp/hadoop-logs
        # 健康检查
        livenessProbe:
          tcpSocket:
            port: 8020
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 8020
          initialDelaySeconds: 30
          periodSeconds: 5
      volumes:
      - name: hadoop-config
        configMap:
          name: hadoop-config
          defaultMode: 0755
      - name: namenode-data
        persistentVolumeClaim:
          claimName: namenode-pvc
      - name: namenode-logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: namenode
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: namenode
  ports:
  - name: webui
    port: 9870
    targetPort: 9870
    nodePort: 30070
  - name: rpc
    port: 8020
    targetPort: 8020
    nodePort: 30071
  - name: datanode-http
    port: 9868
    targetPort: 9868
    nodePort: 30076
---
# 2. Datanode Deployment + Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datanode
  namespace: bigdata2
  labels:
    app: hadoop
    component: datanode
spec:
  replicas: 1  # 可根据需求调整副本数
  selector:
    matchLabels:
      app: hadoop
      component: datanode
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: hadoop
        component: datanode
    spec:
      containers:
      - name: datanode
        image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
        securityContext:
          runAsUser: 0
          runAsGroup: 0
        command: ["/bin/sh", "-c"]
        args:
          - |
            set -e
            # 等待Namenode就绪
            echo "=== 等待Namenode就绪 ==="
            for i in {1..30}; do
              if nc -z namenode 8020; then
                echo "Namenode已就绪！"
                break
              fi
              echo "Namenode未就绪，等待10秒..."
              sleep 10
            done
            # 校验配置文件
            echo "=== 校验配置文件 ==="
            ls -l /opt/hadoop/etc/hadoop/*.xml
            # 确保数据目录存在并授权
            mkdir -p /tmp/hadoop-root/dfs/data
            chmod -R 777 /tmp/hadoop-root/
            # 启动Datanode
            echo "=== 启动Datanode ==="
            hdfs datanode
        ports:
        - containerPort: 9864
        - containerPort: 9866
        - containerPort: 9867
        env:
          - name: HADOOP_HOME
            value: /opt/hadoop
          - name: PATH
            value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
          - name: HADOOP_LOG_DIR
            value: /tmp/hadoop-logs
        volumeMounts:
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/core-site.xml
          subPath: core-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
          subPath: hdfs-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
          subPath: mapred-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
          subPath: yarn-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
          subPath: capacity-scheduler.xml
          readOnly: true
        - name: datanode-data
          mountPath: /tmp/hadoop-root
        - name: datanode-logs
          mountPath: /tmp/hadoop-logs
        # 健康检查
        livenessProbe:
          tcpSocket:
            port: 9867
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 9867
          initialDelaySeconds: 30
          periodSeconds: 5
      volumes:
      - name: hadoop-config
        configMap:
          name: hadoop-config
          defaultMode: 0755
      - name: datanode-data
        persistentVolumeClaim:
          claimName: datanode-pvc
      - name: datanode-logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: datanode
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: datanode
  ports:
  - name: webui
    port: 9864
    targetPort: 9864
    nodePort: 30075
  - name: data-transfer
    port: 9866
    targetPort: 9866
    nodePort: 30077
  - name: ipc
    port: 9867
    targetPort: 9867
---
# 3. ResourceManager Deployment + Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resourcemanager
  namespace: bigdata2
  labels:
    app: hadoop
    component: resourcemanager
spec:
  replicas: 1  # ResourceManager通常单副本
  selector:
    matchLabels:
      app: hadoop
      component: resourcemanager
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: hadoop
        component: resourcemanager
    spec:
      containers:
      - name: resourcemanager
        image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
        securityContext:
          runAsUser: 0
          runAsGroup: 0
        command: ["/bin/sh", "-c"]
        args:
          - |
            set -e
            # 等待Namenode就绪
            echo "=== 等待Namenode就绪 ==="
            for i in {1..30}; do
              if nc -z namenode 8020; then
                echo "Namenode已就绪！"
                break
              fi
              echo "Namenode未就绪，等待10秒..."
              sleep 10
            done
            # 校验配置文件
            echo "=== 校验配置文件 ==="
            ls -l /opt/hadoop/etc/hadoop/*.xml
            # 确保数据目录存在并授权
            mkdir -p /tmp/hadoop-yarn
            chmod -R 777 /tmp/hadoop-yarn
            # 启动ResourceManager
            echo "=== 启动ResourceManager ==="
            yarn resourcemanager
        ports:
        - containerPort: 8088
        - containerPort: 8030
        - containerPort: 8031
        - containerPort: 8032
        env:
          - name: HADOOP_HOME
            value: /opt/hadoop
          - name: PATH
            value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
          - name: HADOOP_LOG_DIR
            value: /tmp/hadoop-logs
        volumeMounts:
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/core-site.xml
          subPath: core-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
          subPath: hdfs-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
          subPath: mapred-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
          subPath: yarn-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
          subPath: capacity-scheduler.xml
          readOnly: true
        - name: resourcemanager-data
          mountPath: /tmp/hadoop-yarn
        - name: test-script
          mountPath: /opt/test.sh
          subPath: test.sh
          readOnly: false
        - name: resourcemanager-logs
          mountPath: /tmp/hadoop-logs
        # 健康检查
        livenessProbe:
          tcpSocket:
            port: 8032
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 8032
          initialDelaySeconds: 30
          periodSeconds: 5
      volumes:
      - name: hadoop-config
        configMap:
          name: hadoop-config
          defaultMode: 0755
      - name: resourcemanager-data
        persistentVolumeClaim:
          claimName: resourcemanager-pvc
      - name: test-script
        configMap:
          name: hadoop-test-script
          defaultMode: 0755
      - name: resourcemanager-logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: resourcemanager
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: resourcemanager
  ports:
  - name: webui
    port: 8088
    targetPort: 8088
    nodePort: 30072
  - name: rpc
    port: 8030
    targetPort: 8030
    nodePort: 30073
  - name: scheduler
    port: 8031
    targetPort: 8031
    nodePort: 30079
  - name: yarn-rpc
    port: 8032
    targetPort: 8032
---
# 4. NodeManager Deployment + Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodemanager
  namespace: bigdata2
  labels:
    app: hadoop
    component: nodemanager
spec:
  replicas: 1  # 可根据需求调整副本数
  selector:
    matchLabels:
      app: hadoop
      component: nodemanager
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: hadoop
        component: nodemanager
    spec:
      containers:
      - name: nodemanager
        image: ccr.ccs.tencentyun.com/hadoop-dev/hadoop:3.1.1
        securityContext:
          runAsUser: 0
          runAsGroup: 0
        command: ["/bin/sh", "-c"]
        args:
          - |
            set -e
            # 等待ResourceManager就绪
            echo "=== 等待ResourceManager就绪 ==="
            for i in {1..30}; do
              if nc -z resourcemanager 8032; then
                echo "ResourceManager已就绪！"
                break
              fi
              echo "ResourceManager未就绪，等待10秒..."
              sleep 10
            done
            # 校验配置文件
            echo "=== 校验配置文件 ==="
            ls -l /opt/hadoop/etc/hadoop/*.xml
            # 确保数据目录存在并授权
            mkdir -p /tmp/hadoop-yarn-nm
            chmod -R 777 /tmp/hadoop-yarn-nm
            # 启动NodeManager
            echo "=== 启动NodeManager ==="
            yarn nodemanager
        ports:
        - containerPort: 8042
        - containerPort: 8040
        env:
          - name: HADOOP_HOME
            value: /opt/hadoop
          - name: PATH
            value: "$PATH:/opt/hadoop/bin:/opt/hadoop/sbin:/usr/bin"
          - name: HADOOP_LOG_DIR
            value: /tmp/hadoop-logs
        volumeMounts:
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/core-site.xml
          subPath: core-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
          subPath: hdfs-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/mapred-site.xml
          subPath: mapred-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/yarn-site.xml
          subPath: yarn-site.xml
          readOnly: true
        - name: hadoop-config
          mountPath: /opt/hadoop/etc/hadoop/capacity-scheduler.xml
          subPath: capacity-scheduler.xml
          readOnly: true
        - name: nodemanager-data
          mountPath: /tmp/hadoop-yarn-nm
        - name: nodemanager-logs
          mountPath: /tmp/hadoop-logs
        # 健康检查
        livenessProbe:
          tcpSocket:
            port: 8040
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 8040
          initialDelaySeconds: 30
          periodSeconds: 5
      volumes:
      - name: hadoop-config
        configMap:
          name: hadoop-config
          defaultMode: 0755
      - name: nodemanager-data
        persistentVolumeClaim:
          claimName: nodemanager-pvc
      - name: nodemanager-logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: nodemanager
  namespace: bigdata2
spec:
  type: NodePort
  selector:
    app: hadoop
    component: nodemanager
  ports:
  - name: webui
    port: 8042
    targetPort: 8042
    nodePort: 30074
  - name: localizer
    port: 8040
    targetPort: 8040
    nodePort: 30078
